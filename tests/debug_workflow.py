"""
è°ƒè¯•å·¥ä½œæµ
"""

import asyncio
from loguru import logger
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from models import WorkflowStatus
from nodes import (
    keyword_generation_node,
    topic_search_node,
    topic_refinement_node,
    post_retrieval_node,
    content_filtering_node,
    hitpoint_analysis_node,
    user_selection_node,
    content_generation_node
)
from config import config

async def debug_workflow():
    """è°ƒè¯•å·¥ä½œæµ"""
    logger.info("ğŸš€ å¼€å§‹è°ƒè¯•å·¥ä½œæµ...")
    
    try:
        # éªŒè¯é…ç½®
        if not config.validate_config():
            logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥")
            return
        
        logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
        
        # åˆ›å»ºå†…å­˜æ£€æŸ¥ç‚¹
        memory = MemorySaver()
        
        # åˆ›å»ºå·¥ä½œæµå›¾
        logger.info("ğŸ”§ æ„å»ºå·¥ä½œæµå›¾...")
        workflow = StateGraph({
            "user_input": str,
            "current_state": str,
            "keywords": list,
            "primary_keyword": str,
            "secondary_keyword": str,
            "topics": list,
            "search_results": dict,
            "retrieved_posts": list,
            "filtered_posts": list,
            "hitpoints": list,
            "generated_content": dict,
            "error_message": str,
            "total_posts_processed": int,
            "total_hitpoints_generated": int,
            "selected_hitpoint": dict
        })
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("keyword_generation", keyword_generation_node)
        workflow.add_node("topic_search", topic_search_node)
        workflow.add_node("topic_refinement", topic_refinement_node)
        workflow.add_node("post_retrieval", post_retrieval_node)
        workflow.add_node("content_filtering", content_filtering_node)
        workflow.add_node("hitpoint_analysis", hitpoint_analysis_node)
        workflow.add_node("user_selection", user_selection_node)
        workflow.add_node("content_generation", content_generation_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("keyword_generation")
        
        # ä½¿ç”¨ç®€å•çš„çº¿æ€§æµç¨‹
        workflow.add_edge("keyword_generation", "topic_search")
        workflow.add_edge("topic_search", "topic_refinement")
        workflow.add_edge("topic_refinement", "post_retrieval")
        workflow.add_edge("post_retrieval", "content_filtering")
        workflow.add_edge("content_filtering", "hitpoint_analysis")
        workflow.add_edge("hitpoint_analysis", "user_selection")
        workflow.add_edge("user_selection", "content_generation")
        workflow.add_edge("content_generation", END)
        
        # ç¼–è¯‘å·¥ä½œæµ
        compiled_workflow = workflow.compile(checkpointer=memory)
        logger.info("âœ… å·¥ä½œæµå›¾æ„å»ºå®Œæˆ")
        
        # æµ‹è¯•ç”¨æˆ·è¾“å…¥
        user_input = "ç¾é£Ÿåˆ¶ä½œ"
        logger.info(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        
        # åˆ›å»ºåˆå§‹çŠ¶æ€
        initial_state = {
            "user_input": user_input,
            "current_state": WorkflowStatus.INITIALIZED.value,
            "keywords": [],
            "primary_keyword": "",
            "secondary_keyword": "",
            "topics": [],
            "search_results": {},
            "retrieved_posts": [],
            "filtered_posts": [],
            "hitpoints": [],
            "generated_content": {},
            "error_message": "",
            "total_posts_processed": 0,
            "total_hitpoints_generated": 0,
            "selected_hitpoint": {}
        }
        logger.info(f"ğŸ“Š åˆå§‹çŠ¶æ€: {initial_state}")
        
        # è¿è¡Œå·¥ä½œæµ
        logger.info("ğŸ”„ å¼€å§‹è¿è¡Œå·¥ä½œæµ...")
        result = await compiled_workflow.ainvoke(initial_state)
        
        logger.info(f"ğŸ“Š ç»“æœç±»å‹: {type(result)}")
        logger.info(f"ğŸ“Š ç»“æœå†…å®¹: {result}")
        
        if result is None:
            logger.error("âŒ å·¥ä½œæµè¿”å›äº†None")
        else:
            logger.info("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
            
            # æ‰“å°ç»“æœæ‘˜è¦
            current_state = result.get("current_state", "æœªçŸ¥")
            error_message = result.get("error_message", "")
            
            if error_message:
                logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå‡ºé”™: {error_message}")
            else:
                logger.info(f"âœ… å·¥ä½œæµçŠ¶æ€: {current_state}")
                
                # æ‰“å°å…³é”®ä¿¡æ¯
                keywords = result.get("keywords", [])
                topics = result.get("topics", [])
                hitpoints = result.get("hitpoints", [])
                generated_content = result.get("generated_content", {})
                
                logger.info(f"ğŸ”‘ ç”Ÿæˆå…³é”®è¯: {len(keywords)} ä¸ª")
                logger.info(f"ğŸ“š æ‰¾åˆ°ä¸»é¢˜: {len(topics)} ä¸ª")
                logger.info(f"ğŸ’¡ åˆ†æçˆ†ç‚¹: {len(hitpoints)} ä¸ª")
                
                if generated_content:
                    title = generated_content.get("title", "æœªçŸ¥æ ‡é¢˜")
                    logger.info(f"ğŸ“ ç”Ÿæˆå†…å®¹æ ‡é¢˜: {title}")
        
        logger.info("ğŸ‰ è°ƒè¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ è°ƒè¯•å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—æ ¼å¼
    logger.remove()
    logger.add(
        lambda msg: print(msg, end=""),
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    
    # è¿è¡Œè°ƒè¯•
    asyncio.run(debug_workflow()) 