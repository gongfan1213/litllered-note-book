#!/usr/bin/env python3
"""
å·¥ä½œæµèŠ‚ç‚¹æµ‹è¯•è„šæœ¬
æµ‹è¯•å°çº¢ä¹¦èµ·å·æ™ºèƒ½åŠ©æ‰‹çš„å„ä¸ªèŠ‚ç‚¹åŠŸèƒ½
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio
import json
from loguru import logger
from workflow_types import WorkflowState
from nodes.topic_search import (
    topic_search_node_1, topic_search_node_2,
    format_topics_node_1, format_topics_node_2,
    combine_topic_results_node
)
from nodes.post_retrieval import (
    post_retrieval_node_1, post_retrieval_node_2,
    parse_posts_node_1, parse_posts_node_2,
    combine_post_results_node
)
from nodes.content_filter import content_filter_node
from nodes.hitpoint_analysis import hitpoint_analysis_node
from nodes.user_selection import user_selection_node
from nodes.content_generation import content_generation_node
from nodes.topic_refinement import topic_refinement_node
from nodes.keyword_generation import keyword_generation_node
from models import WorkflowState, WorkflowStatus

async def test_keyword_generation():
    """æµ‹è¯•å…³é”®è¯ç”ŸæˆèŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•å…³é”®è¯ç”ŸæˆèŠ‚ç‚¹...")
    print("-" * 50)
    
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    state = WorkflowState(
        user_input="å¤§é¾„å‰©å¥³",
        current_state=WorkflowStatus.INITIALIZED
    )
    
    # è°ƒç”¨å…³é”®è¯ç”ŸæˆèŠ‚ç‚¹
    result_state = await keyword_generation_node(state)
    
    print("âœ… å…³é”®è¯ç”Ÿæˆå®Œæˆ!")
    print(f"ğŸ“ LLMè¾“å‡º: {result_state.llm_output[:100] if result_state.llm_output else ''}...")
    
    return result_state

def test_extract_initial_keywords(state):
    """æµ‹è¯•åˆå§‹å…³é”®è¯æå–"""
    print("\nğŸ” æµ‹è¯•åˆå§‹å…³é”®è¯æå–...")
    print("-" * 50)
    
    from workflow import extract_initial_keywords_node
    
    result_state = extract_initial_keywords_node(state)
    
    print("âœ… å…³é”®è¯æå–å®Œæˆ!")
    print(f"ğŸ“ ä¸»è¦å…³é”®è¯: {result_state.primary_keyword}")
    print(f"ğŸ“ æ¬¡è¦å…³é”®è¯: {result_state.secondary_keyword}")
    
    return result_state

async def test_topic_search_nodes(state):
    """æµ‹è¯•è¯é¢˜æœç´¢èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•è¯é¢˜æœç´¢èŠ‚ç‚¹...")
    print("-" * 50)
    
    # å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªè¯é¢˜æœç´¢
    task1 = topic_search_node_1(state)
    task2 = topic_search_node_2(state)
    
    result1, result2 = await asyncio.gather(task1, task2)
    
    print("âœ… è¯é¢˜æœç´¢å®Œæˆ!")
    print(f"ğŸ“ æœç´¢1ç»“æœ: {result1.topic_search_result_1[:100] if result1.topic_search_result_1 else ''}...")
    print(f"ğŸ“ æœç´¢2ç»“æœ: {result2.topic_search_result_2[:100] if result2.topic_search_result_2 else ''}...")
    
    # æ ¼å¼åŒ–ç»“æœ
    formatted1 = format_topics_node_1(result1)
    formatted2 = format_topics_node_2(result2)
    
    # åˆå¹¶ç»“æœ
    combined_state = formatted1.model_copy()
    # æ‰‹åŠ¨åˆå¹¶çŠ¶æ€
    combined_state.topic_search_result_2 = formatted2.topic_search_result_2
    combined_state.formatted_topics_2 = formatted2.formatted_topics_2
    final_result = combine_topic_results_node(combined_state)
    
    print("âœ… è¯é¢˜ç»“æœæ ¼å¼åŒ–å®Œæˆ!")
    print(f"ğŸ“ åˆå¹¶ç»“æœ: {final_result.combined_topic_results[:200] if final_result.combined_topic_results else ''}...")
    
    return final_result

async def test_topic_refinement(state):
    """æµ‹è¯•è¯é¢˜ç²¾ç‚¼èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•è¯é¢˜ç²¾ç‚¼èŠ‚ç‚¹...")
    print("-" * 50)
    
    result_state = await topic_refinement_node(state)
    
    print("âœ… è¯é¢˜ç²¾ç‚¼å®Œæˆ!")
    print(f"ğŸ“ ç²¾ç‚¼è¾“å‡º: {result_state.refinement_llm_output[:200] if result_state.refinement_llm_output else ''}...")
    
    return result_state

def test_extract_refined_keywords(state):
    """æµ‹è¯•ç²¾ç‚¼å…³é”®è¯æå–"""
    print("\nğŸ” æµ‹è¯•ç²¾ç‚¼å…³é”®è¯æå–...")
    print("-" * 50)
    
    from workflow import extract_refined_keywords_node
    
    result_state = extract_refined_keywords_node(state)
    
    print("âœ… ç²¾ç‚¼å…³é”®è¯æå–å®Œæˆ!")
    print(f"ğŸ“ ç²¾ç‚¼å…³é”®è¯: {result_state.refined_keywords}")
    
    return result_state

async def test_post_retrieval_nodes(state):
    """æµ‹è¯•å¸–å­æ£€ç´¢èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•å¸–å­æ£€ç´¢èŠ‚ç‚¹...")
    print("-" * 50)
    
    # å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªå¸–å­æ£€ç´¢
    task1 = post_retrieval_node_1(state)
    task2 = post_retrieval_node_2(state)
    
    result1, result2 = await asyncio.gather(task1, task2)
    
    print("âœ… å¸–å­æ£€ç´¢å®Œæˆ!")
    print(f"ğŸ“ æ£€ç´¢1ç»“æœç±»å‹: {type(result1.post_retrieval_result_1)}")
    print(f"ğŸ“ æ£€ç´¢2ç»“æœç±»å‹: {type(result2.post_retrieval_result_2)}")
    
    # è§£æç»“æœ
    parsed1 = parse_posts_node_1(result1)
    parsed2 = parse_posts_node_2(result2)
    
    # åˆå¹¶ç»“æœ
    combined_state = parsed1.model_copy()
    # æ‰‹åŠ¨åˆå¹¶çŠ¶æ€
    combined_state.post_retrieval_result_2 = parsed2.post_retrieval_result_2
    combined_state.parsed_posts_2 = parsed2.parsed_posts_2
    final_result = combine_post_results_node(combined_state)
    
    print("âœ… å¸–å­ç»“æœè§£æå®Œæˆ!")
    print(f"ğŸ“ åˆå¹¶åå¸–å­æ•°é‡: {len(final_result.retrieved_posts)}")
    
    return final_result

async def test_content_filter(state):
    """æµ‹è¯•å†…å®¹è¿‡æ»¤èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•å†…å®¹è¿‡æ»¤èŠ‚ç‚¹...")
    print("-" * 50)
    
    result_state = await content_filter_node(state)
    
    print("âœ… å†…å®¹è¿‡æ»¤å®Œæˆ!")
    print(f"ğŸ“ è¿‡æ»¤åå¸–å­æ•°é‡: {len(result_state.filtered_posts)}")
    
    return result_state

async def test_hitpoint_analysis(state):
    """æµ‹è¯•æ‰“ç‚¹åˆ†æèŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•æ‰“ç‚¹åˆ†æèŠ‚ç‚¹...")
    print("-" * 50)
    
    result_state = await hitpoint_analysis_node(state)
    
    print("âœ… æ‰“ç‚¹åˆ†æå®Œæˆ!")
    print(f"ğŸ“ æ‰“ç‚¹åˆ†æè¾“å‡º: {result_state.hitpoints_llm_output[:200] if result_state.hitpoints_llm_output else ''}...")
    
    return result_state

def test_extract_hitpoints(state):
    """æµ‹è¯•æ‰“ç‚¹æå–"""
    print("\nğŸ” æµ‹è¯•æ‰“ç‚¹æå–...")
    print("-" * 50)
    
    from workflow import extract_hitpoints_node
    
    result_state = extract_hitpoints_node(state)
    
    print("âœ… æ‰“ç‚¹æå–å®Œæˆ!")
    print(f"ğŸ“ æå–çš„æ‰“ç‚¹: {result_state.hitpoints}")
    
    return result_state

async def test_user_selection(state):
    """æµ‹è¯•ç”¨æˆ·é€‰æ‹©èŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•ç”¨æˆ·é€‰æ‹©èŠ‚ç‚¹...")
    print("-" * 50)
    
    result_state = await user_selection_node(state)
    
    print("âœ… ç”¨æˆ·é€‰æ‹©å®Œæˆ!")
    print(f"ğŸ“ ç”¨æˆ·é€‰æ‹©è¾“å‡º: {result_state.user_selection_llm_output[:200] if result_state.user_selection_llm_output else ''}...")
    
    return result_state

async def test_content_generation(state):
    """æµ‹è¯•å†…å®¹ç”ŸæˆèŠ‚ç‚¹"""
    print("\nğŸ” æµ‹è¯•å†…å®¹ç”ŸæˆèŠ‚ç‚¹...")
    print("-" * 50)
    
    result_state = await content_generation_node(state)
    
    print("âœ… å†…å®¹ç”Ÿæˆå®Œæˆ!")
    if result_state.generated_content:
        print(f"ğŸ“ ç”Ÿæˆçš„å†…å®¹æ ‡é¢˜: {result_state.generated_content.title}")
        print(f"ğŸ“ ç”Ÿæˆçš„å†…å®¹: {result_state.generated_content.content[:300] if result_state.generated_content.content else ''}...")
    else:
        print("ğŸ“ ç”Ÿæˆçš„å†…å®¹: æ— ")
    
    return result_state

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å·¥ä½œæµèŠ‚ç‚¹")
    print("=" * 60)
    
    try:
        # 1. å…³é”®è¯ç”Ÿæˆ
        state = await test_keyword_generation()
        
        # 2. æå–åˆå§‹å…³é”®è¯
        state = test_extract_initial_keywords(state)
        
        # 3. è¯é¢˜æœç´¢
        state = await test_topic_search_nodes(state)
        
        # 4. è¯é¢˜ç²¾ç‚¼
        state = await test_topic_refinement(state)
        
        # 5. æå–ç²¾ç‚¼å…³é”®è¯
        state = test_extract_refined_keywords(state)
        
        # 6. å¸–å­æ£€ç´¢
        state = await test_post_retrieval_nodes(state)
        
        # 7. å†…å®¹è¿‡æ»¤
        state = await test_content_filter(state)
        
        # 8. æ‰“ç‚¹åˆ†æ
        state = await test_hitpoint_analysis(state)
        
        # 9. æå–æ‰“ç‚¹
        state = test_extract_hitpoints(state)
        
        # 10. ç”¨æˆ·é€‰æ‹©
        state = await test_user_selection(state)
        
        # 11. å†…å®¹ç”Ÿæˆ
        state = await test_content_generation(state)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•å®Œæˆ!")
        print("\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
        print("âœ… å…³é”®è¯ç”Ÿæˆå’Œæå–åŠŸèƒ½æ­£å¸¸")
        print("âœ… è¯é¢˜æœç´¢å’Œç²¾ç‚¼åŠŸèƒ½æ­£å¸¸")
        print("âœ… å¸–å­æ£€ç´¢å’Œè§£æåŠŸèƒ½æ­£å¸¸")
        print("âœ… å†…å®¹è¿‡æ»¤åŠŸèƒ½æ­£å¸¸")
        print("âœ… æ‰“ç‚¹åˆ†æåŠŸèƒ½æ­£å¸¸")
        print("âœ… ç”¨æˆ·é€‰æ‹©åŠŸèƒ½æ­£å¸¸")
        print("âœ… å†…å®¹ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
        print("âœ… æ¨¡æ‹Ÿæ•°æ®å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥æµ‹è¯•åç»­èŠ‚ç‚¹")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 