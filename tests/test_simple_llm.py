#!/usr/bin/env python3
"""
ç®€åŒ–çš„LLMè¿æ¥æµ‹è¯•è„šæœ¬
"""

import asyncio
from loguru import logger
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from config import config

async def test_simple_llm():
    """ç®€å•çš„LLMæµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹ç®€å•LLMæµ‹è¯•...")
    
    try:
        # ç›´æ¥åˆ›å»ºChatOpenAIå®ä¾‹
        llm = ChatOpenAI(
            model=config.DEFAULT_MODEL,
            openai_api_base=config.LLM_BASE_URL,
            openai_api_key=config.LLM_API_KEY,
            temperature=0.7,
            max_tokens=100
        )
        
        # å‘é€ç®€å•æµ‹è¯•æ¶ˆæ¯
        response = await llm.ainvoke([
            HumanMessage(content="ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯å›å¤æˆ‘ã€‚")
        ])
        
        print(f"âœ… LLMè¿æ¥æˆåŠŸï¼")
        print(f"   å“åº”: {response.content}")
        return True
        
    except Exception as e:
        print(f"âŒ LLMè¿æ¥å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    asyncio.run(test_simple_llm()) 